{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import skimage\n",
    "import imantics\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = 'Mask_RCNN-master 3'\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import Cell\n",
    "\n",
    "import imantics\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function taken from utils.dataset\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = skimage.io.imread(image_path)\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if image.ndim != 3:\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "    # If has an alpha channel, remove it for consistency\n",
    "    if image.shape[-1] == 4:\n",
    "        image = image[..., :3]\n",
    "    return image\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    ,\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"\n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images moved and predictions saved...\n",
      "Open VIA and update any missing annotations for BOTH training and validation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import skimage\n",
    "iteration = 0 #modify to resume at iteration\n",
    "current_count = 30\n",
    "iteration_folder = os.path.abspath(\"../iterations/\") + \"/\"\n",
    "\n",
    "dataset = Cell.HSYAADataset()\n",
    "dataset.load_data(\"dataset/\", \"train\")\n",
    "dataset.prepare()\n",
    "\n",
    "batch_size = 10 #Small batch sizes early, large batch sizes later\n",
    "validation_percent = 50 # Typically 10% but larger for very small datasets\n",
    "\n",
    "time_per_trap = 391\n",
    "beacon = 8\n",
    "traps_folder = \"/home/ubuntu/github/HSYAA_GT/IM_with_GT/BC8_good_gray/Trap010/\"\n",
    "output_folder = \"/Users/trevorpeyton/Documents/github/HSYAA_GT/IM_with_GT/predicted/\"\n",
    "image_format = \"rf02032017_TL1444143_BC%d_Tp%.3dTm%.3d.jpg\"\n",
    "traps = [o[-3:] for o in os.listdir(traps_folder) if os.path.isdir(os.path.join(traps_folder,o))]\n",
    "\n",
    "generate_batch = False\n",
    "\n",
    "annotation_train_json = {}\n",
    "annotation_val_json = {}\n",
    "\n",
    "while(input(\"Press s to begin next iteration. Press anything else to stop.\") == 's'):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(\"Creating iteration...\")\n",
    "    \n",
    "    if iteration > 0:\n",
    "        if not os.path.exists(iteration_folder + \"iteration%.3d\" % (iteration - 1)):\n",
    "            print(\"Error: the last iteration (%.3d) doesn't exist.\" % (iteration - 1))\n",
    "            print(\"Stopping...\")\n",
    "            break\n",
    "    \n",
    "    current_iteration_folder = iteration_folder + \"iteration%.3d/\" % iteration\n",
    "    \n",
    "    if not os.path.exists(current_iteration_folder):\n",
    "        os.mkdir(current_iteration_folder)\n",
    "        os.mkdir(current_iteration_folder + \"/dataset/\")\n",
    "        os.mkdir(current_iteration_folder + \"/dataset/train/\")\n",
    "        os.mkdir(current_iteration_folder + \"/dataset/val/\")\n",
    "    elif os.path.exists(current_iteration_folder + \"final_iteration_model.h5\"):\n",
    "        if input(\"Iteration already exists would you like to skip to the next? y/n\") == \"y\":\n",
    "            iteration += 1\n",
    "        \n",
    "    print(\"Loading model...\")\n",
    "    \n",
    "    training_folder = os.path.abspath(current_iteration_folder + \"dataset/train/\") + \"/\"\n",
    "    val_folder = os.path.abspath(current_iteration_folder + \"dataset/val/\") + \"/\"\n",
    "    \n",
    "    model_dir = model_file = model_path = \"\"\n",
    "    if iteration == 0:\n",
    "        model_dir = \"../logs/cell20200529T1324/\"\n",
    "        model_file = \"mask_rcnn_cell_0050.h5\"\n",
    "        model_path = os.path.abspath(model_dir + model_file)\n",
    "    else:\n",
    "        model_dir = iteration_folder + \"iteration%.3d/\" % (iteration - 1)\n",
    "        model_file = \"final_iteration_model.h5\"\n",
    "        model_path = os.path.abspath(model_dir + model_file)\n",
    "        \n",
    "    predict_model = modellib.MaskRCNN(mode=\"inference\", config=Cell.config, model_dir=model_dir)\n",
    "    predict_model.load_weights(model_path, by_name=True)\n",
    "    training_model = modellib.MaskRCNN(mode=\"training\", config=Cell.config, model_dir=model_dir)\n",
    "    training_model.load_weights(model_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    \n",
    "    print(\"Generating batch...\")\n",
    "    \n",
    "    debug = {}\n",
    "        \n",
    "    if generate_batch:\n",
    "        batch_size = int(input(\"New batch size:\"))            \n",
    "        validation_percent = int(input(\"New validation percent:\"))\n",
    "    \n",
    "        validation_list = random.sample(range(current_count, current_count + batch_size), int(batch_size * (validation_percent / 100)))\n",
    "        for n in range(current_count, current_count + batch_size):\n",
    "            validation = n in validation_list\n",
    "            trap = int(n / time_per_trap)\n",
    "            time = (n % time_per_trap) + 1\n",
    "            current_count = n\n",
    "\n",
    "            filename = image_format % (beacon, int(traps[trap]), time)\n",
    "            filepath = os.path.join(traps_folder, \"Trap\" + traps[trap], filename)\n",
    "\n",
    "            print(f\"Trap: {traps[trap]}, Time: {time}\")\n",
    "\n",
    "            #Copy\n",
    "            img = cv2.imread(filepath, 0)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            if validation:\n",
    "                cv2.imwrite(current_iteration_folder + \"dataset/val/\" + filename, img)\n",
    "            else:\n",
    "                cv2.imwrite(current_iteration_folder + \"dataset/train/\" + filename, img)\n",
    "\n",
    "            # Run object detection\n",
    "            results = predict_model.detect([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)], verbose=1)\n",
    "\n",
    "            # Display results\n",
    "            #ax = get_ax(1)\n",
    "            r = results[0]\n",
    "\n",
    "            a = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                       dataset.class_names, r['scores'], ax=ax,\n",
    "                                       title=\"Predictions\", path=os.path.join(new_output_folder, filename))\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            regions = []\n",
    "\n",
    "            for n in range(r['masks'].shape[2]):\n",
    "                poly = imantics.Polygons.from_mask(imantics.Mask(r['masks'][:, :, n]))\n",
    "                points = [y for x in poly.segmentation for y in x]\n",
    "                try:\n",
    "                    regions.append({\n",
    "                            \"shape_attributes\": {\n",
    "                                \"name\": \"polygon\",\n",
    "                                \"all_points_x\": points[::2],\n",
    "                                \"all_points_y\": points[1::2]\n",
    "                            },\n",
    "                            \"region_attributes\": {\n",
    "                                \"name\": dataset.class_names[r['class_ids'][n]]\n",
    "                            }\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    mask = r['masks'][:, :, n]\n",
    "                    print(points)\n",
    "                    \n",
    "                    if hasattr(e, 'message'):\n",
    "                        print(e.message)\n",
    "                    else:\n",
    "                        print(e)\n",
    "                        \n",
    "                    _ = input(\"\")\n",
    "\n",
    "            file_annotations = {\n",
    "                    \"filename\": filename,\n",
    "                    \"regions\": regions,\n",
    "                    \"file_attributes\": {}\n",
    "                }\n",
    "\n",
    "            if validation:\n",
    "                annotation_val_json[filename] = file_annotations\n",
    "            else:\n",
    "                annotation_train_json[filename] = file_annotations\n",
    "\n",
    "        via_project = {\n",
    "            \"_via_settings\": {\n",
    "                \"ui\": {\n",
    "                    \"annotation_editor_height\": 25,\n",
    "                    \"annotation_editor_fontsize\": 0.8,\n",
    "                    \"leftsidebar_width\": 18,\n",
    "                    \"image_grid\": {\n",
    "                        \"img_height\": 80,\n",
    "                        \"rshape_fill\": \"none\",\n",
    "                        \"rshape_fill_opacity\": 0.3,\n",
    "                        \"rshape_stroke\": \"yellow\",\n",
    "                        \"rshape_stroke_width\": 2,\n",
    "                        \"show_region_shape\": True,\n",
    "                        \"show_image_policy\": \"all\"\n",
    "                    },\n",
    "                    \"image\": {\n",
    "                        \"region_label\": \"__via_region_id__\",\n",
    "                        \"region_color\": \"__via_default_region_color__\",\n",
    "                        \"region_label_font\": \"10px Sans\",\n",
    "                        \"on_image_annotation_editor_placement\": \"NEAR_REGION\"\n",
    "                    }\n",
    "                },\n",
    "                \"core\": {\n",
    "                    \"buffer_size\": \"18\",\n",
    "                    \"filepath\": {},\n",
    "                    \"default_filepath\": \"\"\n",
    "                },\n",
    "                \"project\": {\n",
    "                    \"name\": \"via_project_with\"\n",
    "                }\n",
    "            },\n",
    "            \"_via_img_metadata\": {},\n",
    "            \"_via_attributes\": {\n",
    "                \"region\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                },\n",
    "                \"file\": {}\n",
    "                \n",
    "            }\n",
    "        }\n",
    "\n",
    "        via_project[\"_via_img_metadata\"] = annotation_train_json\n",
    "        via_project[\"_via_settings\"][\"core\"][\"default_filepath\"] = training_folder\n",
    "        print(current_iteration_folder)\n",
    "        with open(current_iteration_folder + 'dataset/train/via_project.json', 'w') as outfile:\n",
    "            json.dump(via_project, outfile)\n",
    "\n",
    "        via_project[\"_via_img_metadata\"] = annotation_val_json\n",
    "        via_project[\"_via_settings\"][\"core\"][\"default_filepath\"] = val_folder\n",
    "        with open(current_iteration_folder + 'dataset/val/via_project.json', 'w') as outfile:\n",
    "            json.dump(via_project, outfile)\n",
    "            \n",
    "    generate_batch = True\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(\"Images moved and predictions saved...\")\n",
    "    \n",
    "    print(\"Open VIA and update any missing annotations for BOTH training and validation.\")\n",
    "    \n",
    "    input(\"Type anything to continue once you have updated all the missing annotations AND exported as json and overriden the via_export_json.json\")\n",
    "    \n",
    "    input(\"Buffer input just for safety\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    epochs = int(input(\"Epochs?\"))\n",
    "    \n",
    "    print(\"Training based on new annotations\")\n",
    "    \n",
    "    Cell.train(training_model, training_model.epoch + epochs, os.path.abspath(current_iteration_folder + \"dataset/\") + \"/\")\n",
    "    \n",
    "    training_model.keras_model.save_weights(current_iteration_folder + \"final_iteration_model.h5\")\n",
    "    \n",
    "    print(\"Saved\")\n",
    "    \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
